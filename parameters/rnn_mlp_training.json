{
    "n_epochs" : 15,
    "batch_size": 32 ,
    "obs_length": 8,
    "pred_length"  : 12,
    "seq_length"  : 20,
    "nb_samples" : 9892,
    "num_workers" : 0,
    "lr" : 0.001, 
    "load_path" : "",    
    "plot": 1,
    "input_dim":2,
    "hidden_size":32,
    "recurrent_layer":1,
    "mlp_layers":[100],
    "output_size":24,
    "model_type": 0
}